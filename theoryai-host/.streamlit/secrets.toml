# Hugging Face Configuration
LLM_BASE_URL = "https://api-inference.huggingface.co/models/meta-llama/Llama-2-7b-chat-hf"
HF_TOKEN = "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"
LLM_MODEL = "meta-llama/Llama-2-7b-chat-hf"
LLM_TEMPERATURE = "0.05"
LLM_TIMEOUT = "300"
MAX_RESPONSE_TOKENS = "1500"

SEARCH_LIMIT = "20"
RELEVANCE_THRESHOLD = "0.1"
MAX_CONTEXT_LENGTH = "4000"
CHUNK_OVERLAP_RANGE = "3"

BATCH_SIZE = "1000"
MAX_SCAN_LIMIT = "50000"
ENABLE_CACHING = "1"

MIN_CHUNK_RELEVANCE = "0.08"
MAX_BOOKS_PER_RESPONSE = "5"
ENABLE_HALLUCINATION_CHECK = "1"

CONVERSATION_HISTORY_LIMIT = "6"
HISTORY_CONTENT_LIMIT = "150"